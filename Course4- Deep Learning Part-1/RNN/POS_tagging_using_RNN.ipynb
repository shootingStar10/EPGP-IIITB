{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vht4r_ywQcz2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import keras\n",
        "import gensim\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download POS data\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('treebank')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('punkt')\n",
        "nltk.download('universal_tagset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh7ZcGTHQ4aq",
        "outputId": "3517a272-1e7a-4423-deb4-4d87f865c353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "sjr-Gxhbonq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown, treebank, conll2000"
      ],
      "metadata": {
        "id": "w-yYSZQWRHvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
        "brown_corpus = brown.tagged_sents(tagset='universal')\n",
        "conll_corpus = conll2000.tagged_sents(tagset='universal')"
      ],
      "metadata": {
        "id": "plYcMJ_-gIhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus\n",
        "tagged_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WfwJARIhqem",
        "outputId": "6f5f8cdf-d453-455e-d61e-101ec7a52a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NOUN'),\n",
              " ('Vinken', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('61', 'NUM'),\n",
              " ('years', 'NOUN'),\n",
              " ('old', 'ADJ'),\n",
              " (',', '.'),\n",
              " ('will', 'VERB'),\n",
              " ('join', 'VERB'),\n",
              " ('the', 'DET'),\n",
              " ('board', 'NOUN'),\n",
              " ('as', 'ADP'),\n",
              " ('a', 'DET'),\n",
              " ('nonexecutive', 'ADJ'),\n",
              " ('director', 'NOUN'),\n",
              " ('Nov.', 'NOUN'),\n",
              " ('29', 'NUM'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create X and y\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for sentence in tagged_sentences:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "  X.append(X_sentence)\n",
        "  y.append(y_sentence)\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Sentence': X,\n",
        "    'Tags': y\n",
        "})"
      ],
      "metadata": {
        "id": "dSHLOu7Thy1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "XxWAfWJlp0Yq",
        "outputId": "732a2ef6-4433-4458-83a0-9a79111b1954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  \\\n",
              "0  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3  [A, form, of, asbestos, once, used, *, *, to, ...   \n",
              "4  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                                Tags  \n",
              "0  [NOUN, NOUN, ., NUM, NOUN, ADJ, ., VERB, VERB,...  \n",
              "1  [NOUN, NOUN, VERB, NOUN, ADP, NOUN, NOUN, ., D...  \n",
              "2  [NOUN, NOUN, ., NUM, NOUN, ADJ, CONJ, ADJ, NOU...  \n",
              "3  [DET, NOUN, ADP, NOUN, ADV, VERB, X, X, PRT, V...  \n",
              "4  [DET, NOUN, NOUN, ., NOUN, ., VERB, ADV, ADJ, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e5e6f8e-2d27-4738-b45c-477ddd9ce706\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NOUN, NOUN, ., NUM, NOUN, ADJ, ., VERB, VERB,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NOUN, NOUN, VERB, NOUN, ADP, NOUN, NOUN, ., D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NOUN, NOUN, ., NUM, NOUN, ADJ, CONJ, ADJ, NOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[A, form, of, asbestos, once, used, *, *, to, ...</td>\n",
              "      <td>[DET, NOUN, ADP, NOUN, ADV, VERB, X, X, PRT, V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DET, NOUN, NOUN, ., NOUN, ., VERB, ADV, ADJ, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e5e6f8e-2d27-4738-b45c-477ddd9ce706')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e5e6f8e-2d27-4738-b45c-477ddd9ce706 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e5e6f8e-2d27-4738-b45c-477ddd9ce706');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65cea43a-604f-459f-bb46-e2dfea030032\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65cea43a-604f-459f-bb46-e2dfea030032')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65cea43a-604f-459f-bb46-e2dfea030032 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 72202,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
        "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
        "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
        "print(\"Length of first output sequence : {}\".format(len(y[0])))"
      ],
      "metadata": {
        "id": "XtP8rRXIp3oD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3ba5e0-678d-4647-d8de-fe08e6a481d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of first input sequence  : 18\n",
            "Length of first output sequence : 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorise X and Y"
      ],
      "metadata": {
        "id": "DEbhcIRZcKJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "EaLr2C5AcOnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode X\n",
        "\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X)\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "IMPaPdvFcdKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode Y\n",
        "\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y)\n",
        "Y_encoded = tag_tokenizer.texts_to_sequences(y)"
      ],
      "metadata": {
        "id": "BqPmxYzVcvzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*75, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*75, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', Y_encoded[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHA5VgVpdMPL",
        "outputId": "7a53006d-df82-452a-d08e-e917d5b72630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Raw data point ** \n",
            " --------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " --------------------------------------------------------------------------- \n",
            "\n",
            "X:  [6423, 24231, 2, 7652, 102, 170, 2, 47, 1898, 1, 269, 17, 7, 13230, 619, 1711, 2761, 3] \n",
            "\n",
            "Y:  [1, 1, 3, 11, 1, 6, 3, 2, 2, 5, 1, 4, 5, 6, 1, 1, 11, 3] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure that each sequence of input and output is same length\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded, Y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzzZKbobdzhE",
        "outputId": "665fcef6-1173-41d7-e27e-27843fbb92c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pad sequences\n",
        "\n",
        "The next step after encoding the data is to define the sequence lengths. As of now, the sentences present in the data are of various lengths. We need to either pad short sentences or truncate long sentences to a fixed length. This fixed length, however, is a hyperparameter."
      ],
      "metadata": {
        "id": "u2F2oL2whvgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get maximum length of sequence\n",
        "\n",
        "seq_len = [len(seq) for seq in X_encoded]\n",
        "print('Max sequence length:', max(seq_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIzvOYofeDmc",
        "outputId": "200daf81-d49c-4cda-b5f6-f4d6b2d15287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length: 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function.\n",
        "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
        "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'.\n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_SEQ_LENGTH = 100  # sequences greater than 100 in length will be truncated\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
        "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "OUMPfEmylq8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\"*3)\n",
        "print(Y_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr_PpZF1l8K9",
        "outputId": "d017d4c7-3da5-405f-df03-1c3492f2f0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0  6423 24231\n",
            "     2  7652   102   170     2    47  1898     1   269    17     7 13230\n",
            "   619  1711  2761     3] \n",
            "\n",
            "\n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  1  1  3 11  1  6  3  2  2  5  1  4  5  6\n",
            "  1  1 11  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign padded sequences to X and Y\n",
        "X, Y = X_padded, Y_padded"
      ],
      "metadata": {
        "id": "wZ3zp0kkmJAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word embeddings\n",
        "\n",
        "Currently, each word and each tag is encoded as an integer.\n",
        "\n",
        "We'll use a more sophisticated technique to represent the input words (X) using what's known as word embeddings.\n",
        "\n",
        "However, to represent each tag in Y, we'll simply use one-hot encoding scheme since there are only 13 tags in the dataset and the LSTM will have no problems in learning its own representation of these tags.\n",
        "\n",
        "To use word embeddings, you can go for either of the following models:\n",
        "\n",
        "word2vec model: https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "GloVe model : https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "We're using the word2vec model for no particular reason. Both of these are very efficient in representing words. You can try both and see which one works better.\n",
        "\n",
        "Dimensions of a word embedding is: (VOCABULARY_SIZE, EMBEDDING_DIMENSION)"
      ],
      "metadata": {
        "id": "e21liva0pEkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import word embeddings\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxG27YMUmNvm",
        "outputId": "a2005de2-8c1d-4e8f-f1c8-5edd71725725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "metadata": {
        "id": "O_y4jUIBqbLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# load word2vec using the following function present in the gensim library\n",
        "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)"
      ],
      "metadata": {
        "id": "erjlKSaorCkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec effectiveness\n",
        "word2vec.most_similar(positive = [\"King\", \"Woman\"], negative = [\"Man\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xGR_hLdrHGa",
        "outputId": "38863efc-b6f9-4aa7-d4c0-f3dc4571d34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Queen', 0.4929387867450714),\n",
              " ('Tupou_V.', 0.45174285769462585),\n",
              " ('Oprah_BFF_Gayle', 0.4422132968902588),\n",
              " ('Jackson', 0.440250426530838),\n",
              " ('NECN_Alison', 0.4331282675266266),\n",
              " ('Whitfield', 0.42834725975990295),\n",
              " ('Ida_Vandross', 0.42084527015686035),\n",
              " ('prosecutor_Dan_Satterberg', 0.420758992433548),\n",
              " ('martin_Luther_King', 0.42059651017189026),\n",
              " ('Coretta_King', 0.4202733635902405)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign word vectors from word2vec model\n",
        "\n",
        "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
        "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "# create an empty embedding matix\n",
        "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
        "\n",
        "# create a word to index dictionary mapping\n",
        "word2id = word_tokenizer.word_index\n",
        "\n",
        "# copy vectors from word2vec model to the words present in corpus\n",
        "for word, index in word2id.items():\n",
        "    try:\n",
        "        embedding_weights[index, :] = word2vec[word]\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "metadata": {
        "id": "tNBQfZl2roex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check embedding dimension\n",
        "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIuM-PBuryQK",
        "outputId": "abf2d364-2d85-4900-91ba-8d2fb2060995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (59449, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at an embedding of a word\n",
        "embedding_weights[word_tokenizer.word_index['joy']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bhpbJJumr5t5",
        "outputId": "abd8ce07-8abf-4e3d-9dc1-b9cc1ee94034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.4453125 , -0.20019531,  0.20019531, -0.03149414,  0.078125  ,\n",
              "       -0.390625  ,  0.13671875, -0.13867188,  0.05395508,  0.10546875,\n",
              "       -0.05029297, -0.23730469,  0.19921875,  0.12597656, -0.12695312,\n",
              "        0.34179688,  0.06347656,  0.26757812, -0.07324219, -0.29101562,\n",
              "        0.10498047,  0.11914062,  0.23730469,  0.00640869,  0.12451172,\n",
              "       -0.00939941, -0.02770996,  0.03076172,  0.07421875, -0.22851562,\n",
              "       -0.08056641, -0.05273438,  0.16894531,  0.19824219, -0.15625   ,\n",
              "       -0.08740234,  0.10742188, -0.07177734,  0.05200195,  0.25976562,\n",
              "        0.171875  , -0.13574219,  0.06738281,  0.00531006,  0.15527344,\n",
              "       -0.03515625,  0.08789062,  0.3359375 , -0.12890625,  0.17578125,\n",
              "       -0.08642578,  0.32421875, -0.09033203,  0.35351562,  0.24316406,\n",
              "       -0.07470703, -0.06640625, -0.17578125,  0.06689453, -0.03833008,\n",
              "        0.0100708 , -0.21484375, -0.03686523,  0.04394531,  0.02209473,\n",
              "        0.00219727, -0.22460938,  0.03015137, -0.21582031,  0.16015625,\n",
              "        0.23339844, -0.16699219, -0.09228516,  0.10644531,  0.19335938,\n",
              "       -0.26757812,  0.15722656, -0.08691406,  0.11181641,  0.14941406,\n",
              "       -0.20507812,  0.04882812, -0.07519531, -0.21582031, -0.10107422,\n",
              "       -0.13378906, -0.06103516,  0.05444336,  0.07470703,  0.09521484,\n",
              "       -0.0144043 ,  0.27929688, -0.25585938, -0.05273438, -0.22460938,\n",
              "        0.10253906, -0.15136719,  0.21289062, -0.04711914, -0.12109375,\n",
              "        0.04663086,  0.25976562,  0.13574219,  0.00799561,  0.02001953,\n",
              "        0.1796875 ,  0.30664062,  0.06152344,  0.13574219, -0.09619141,\n",
              "       -0.07421875,  0.38671875,  0.20800781,  0.12695312,  0.05200195,\n",
              "        0.17675781, -0.16796875, -0.19335938, -0.06152344, -0.07568359,\n",
              "       -0.18457031,  0.06030273, -0.15136719, -0.1953125 , -0.23339844,\n",
              "        0.00738525, -0.02478027, -0.09765625, -0.06054688,  0.20214844,\n",
              "       -0.2734375 ,  0.00595093, -0.34570312, -0.12988281,  0.00418091,\n",
              "        0.09960938,  0.0246582 ,  0.15917969, -0.02038574,  0.30273438,\n",
              "       -0.20800781, -0.20214844, -0.03930664, -0.06494141,  0.00436401,\n",
              "       -0.02270508, -0.171875  ,  0.30273438, -0.16113281, -0.49414062,\n",
              "        0.3515625 ,  0.39257812,  0.09814453,  0.41796875,  0.05371094,\n",
              "        0.02392578, -0.03710938, -0.08251953, -0.38671875, -0.40625   ,\n",
              "       -0.05664062,  0.203125  , -0.01782227,  0.3359375 ,  0.19140625,\n",
              "       -0.44335938,  0.00927734,  0.24804688, -0.05102539,  0.19726562,\n",
              "        0.03881836,  0.03442383, -0.40039062, -0.09912109, -0.07128906,\n",
              "        0.21484375, -0.01422119,  0.04907227, -0.07421875, -0.21582031,\n",
              "       -0.41992188,  0.02172852,  0.11083984, -0.33398438, -0.2734375 ,\n",
              "       -0.05322266, -0.16601562, -0.28515625, -0.12207031,  0.04882812,\n",
              "       -0.0625    , -0.04077148, -0.16503906,  0.0480957 , -0.21191406,\n",
              "        0.20019531, -0.2109375 ,  0.10839844, -0.14648438, -0.07958984,\n",
              "       -0.05151367, -0.16601562, -0.24902344, -0.375     ,  0.05664062,\n",
              "       -0.13671875, -0.2578125 ,  0.28515625, -0.04736328,  0.13574219,\n",
              "       -0.14550781,  0.19433594, -0.21972656,  0.08447266, -0.10791016,\n",
              "       -0.11816406, -0.16015625,  0.12060547, -0.10888672,  0.04345703,\n",
              "        0.11474609, -0.08447266, -0.00720215,  0.03662109, -0.38671875,\n",
              "       -0.03881836, -0.03198242,  0.00344849,  0.22558594, -0.06787109,\n",
              "       -0.16699219,  0.2421875 ,  0.05712891,  0.27539062, -0.0456543 ,\n",
              "       -0.19042969, -0.17285156,  0.00836182, -0.03271484,  0.16992188,\n",
              "       -0.18554688, -0.0703125 , -0.32617188, -0.00668335, -0.02770996,\n",
              "        0.3359375 ,  0.125     , -0.2109375 ,  0.06005859, -0.07080078,\n",
              "        0.11132812,  0.125     ,  0.25390625,  0.29296875, -0.03125   ,\n",
              "        0.09033203, -0.20507812, -0.07861328,  0.02062988, -0.0546875 ,\n",
              "       -0.23339844,  0.00096893, -0.04516602,  0.16894531, -0.22167969,\n",
              "        0.08105469,  0.33398438,  0.09619141,  0.00866699, -0.03271484,\n",
              "        0.05493164,  0.12109375,  0.16210938, -0.10302734,  0.27148438,\n",
              "       -0.03344727, -0.30273438,  0.04223633,  0.08496094, -0.15527344,\n",
              "        0.10107422, -0.11474609, -0.13085938,  0.22949219,  0.12988281,\n",
              "        0.09863281, -0.03588867,  0.10693359, -0.24902344,  0.19238281,\n",
              "       -0.05322266, -0.09033203, -0.31640625, -0.5703125 , -0.15917969,\n",
              "        0.0291748 , -0.0246582 , -0.07714844, -0.04663086, -0.17578125])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use one-hot encoding for output sequences (Y)"
      ],
      "metadata": {
        "id": "Ie-oshgYsFms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# use Keras' to_categorical function to one-hot encode Y\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNb7DfMIr_TC",
        "outputId": "cc1570aa-5118-4f16-d219-e37fed824980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72202, 100, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data in training, validation and tesing sets¶"
      ],
      "metadata": {
        "id": "RkmL_7D5dEYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4o_9XTtEsmEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=4)"
      ],
      "metadata": {
        "id": "zfN1voHSdMnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=0.15, random_state=4)"
      ],
      "metadata": {
        "id": "mzlEDpzSda-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print number of samples in each set\n",
        "print(\"TRAINING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_train.shape))\n",
        "print('Shape of output sequences: {}'.format(Y_train.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"VALIDATION DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_validation.shape))\n",
        "print('Shape of output sequences: {}'.format(Y_validation.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"TESTING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_test.shape))\n",
        "print('Shape of output sequences: {}'.format(Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCXabBVIpV7a",
        "outputId": "adbdac5c-043f-47ca-d4b9-8a876ed9e85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "Shape of input sequences: (52165, 100)\n",
            "Shape of output sequences: (52165, 100, 13)\n",
            "--------------------------------------------------\n",
            "VALIDATION DATA\n",
            "Shape of input sequences: (9206, 100)\n",
            "Shape of output sequences: (9206, 100, 13)\n",
            "--------------------------------------------------\n",
            "TESTING DATA\n",
            "Shape of input sequences: (10831, 100)\n",
            "Shape of output sequences: (10831, 100, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using RNN, we must make sure the dimensions of the data are what an RNN expects. In general, an RNN expects the following shape\n",
        "\n",
        "Shape of X: (#samples, #timesteps, #features)\n",
        "\n",
        "Shape of Y: (#samples, #timesteps, #features)\n",
        "\n",
        "## Vanila RNN\n",
        "\n",
        "### Arbitrarily initialised, untrainable embeddings\n",
        "\n",
        "First let's try running a vanilla RNN. For this RNN we won't use the pre-trained word embeddings. We'll use randomly inititalised embeddings. Moreover, we won't update the embeddings weights."
      ],
      "metadata": {
        "id": "My0CyVoLqInb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total number of tags\n",
        "NUM_CLASSES = Y.shape[2]"
      ],
      "metadata": {
        "id": "NrWH7lLEqJXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, TimeDistributed, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# create architecture\n",
        "\n",
        "rnn_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        trainable     =  False                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "rnn_model.add(SimpleRNN(64,\n",
        "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "WRqP9s2sqf8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo4Z-nrirPnI",
        "outputId": "02c4db90-7541-46ae-abc5-ee972f0d29e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100, 64)           23360     \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 100, 13)           845       \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17858905 (68.13 MB)\n",
            "Trainable params: 24205 (94.55 KB)\n",
            "Non-trainable params: 17834700 (68.03 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "R53YtXSFrUDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htA-XXo1rjcQ",
        "outputId": "0c575440-849f-4cfa-d535-9a0db7fe70eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "408/408 [==============================] - 17s 39ms/step - loss: 0.4900 - accuracy: 0.8578 - val_loss: 0.3363 - val_accuracy: 0.8966\n",
            "Epoch 2/10\n",
            "408/408 [==============================] - 16s 38ms/step - loss: 0.2782 - accuracy: 0.9152 - val_loss: 0.2349 - val_accuracy: 0.9289\n",
            "Epoch 3/10\n",
            "408/408 [==============================] - 16s 39ms/step - loss: 0.2127 - accuracy: 0.9341 - val_loss: 0.1917 - val_accuracy: 0.9394\n",
            "Epoch 4/10\n",
            "408/408 [==============================] - 16s 39ms/step - loss: 0.1807 - accuracy: 0.9424 - val_loss: 0.1681 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "408/408 [==============================] - 16s 39ms/step - loss: 0.1615 - accuracy: 0.9478 - val_loss: 0.1530 - val_accuracy: 0.9501\n",
            "Epoch 6/10\n",
            "408/408 [==============================] - 15s 38ms/step - loss: 0.1485 - accuracy: 0.9515 - val_loss: 0.1424 - val_accuracy: 0.9531\n",
            "Epoch 7/10\n",
            "408/408 [==============================] - 15s 38ms/step - loss: 0.1396 - accuracy: 0.9538 - val_loss: 0.1354 - val_accuracy: 0.9549\n",
            "Epoch 8/10\n",
            "408/408 [==============================] - 16s 38ms/step - loss: 0.1333 - accuracy: 0.9555 - val_loss: 0.1296 - val_accuracy: 0.9564\n",
            "Epoch 9/10\n",
            "408/408 [==============================] - 16s 38ms/step - loss: 0.1286 - accuracy: 0.9568 - val_loss: 0.1261 - val_accuracy: 0.9569\n",
            "Epoch 10/10\n",
            "408/408 [==============================] - 16s 39ms/step - loss: 0.1251 - accuracy: 0.9578 - val_loss: 0.1227 - val_accuracy: 0.9585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arbitrarily initialised, trainable embeddings"
      ],
      "metadata": {
        "id": "A7ittlq_QQ6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create architecture\n",
        "\n",
        "rnn_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        trainable     =  True                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "rnn_model.add(SimpleRNN(64,\n",
        "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "CZNI7_ySro0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MydH9DhQtZOn",
        "outputId": "525b0b82-a327-4802-c41c-95b194fddca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 100, 64)           23360     \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 100, 13)           845       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17858905 (68.13 MB)\n",
            "Trainable params: 17858905 (68.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "h9PIFyFetbk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=3, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JE7CVoCteCe",
        "outputId": "5e6330af-556a-4d9e-cfc7-ca65c9a4275d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "408/408 [==============================] - 90s 218ms/step - loss: 0.2042 - accuracy: 0.9525 - val_loss: 0.0408 - val_accuracy: 0.9875\n",
            "Epoch 2/3\n",
            "408/408 [==============================] - 89s 218ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0292 - val_accuracy: 0.9898\n",
            "Epoch 3/3\n",
            "408/408 [==============================] - 89s 219ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0271 - val_accuracy: 0.9903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainable word2vec embeddings"
      ],
      "metadata": {
        "id": "cq8L7e3Fx5Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create architecture\n",
        "\n",
        "rnn_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        weights       =  [embedding_weights],     # word embedding matrix\n",
        "                        trainable     =  True                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "rnn_model.add(SimpleRNN(64,\n",
        "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "oMa8HTiJwX7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNHXvpYgyJ0E",
        "outputId": "483aab9e-a8a0-4dd3-def1-f3bb3ccd4af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 100, 64)           23360     \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 100, 13)           845       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17858905 (68.13 MB)\n",
            "Trainable params: 17858905 (68.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1c5ak9ZdyLpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1_k16RZyO_z",
        "outputId": "80df986c-7dec-4798-aa39-c54344084159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "408/408 [==============================] - 91s 220ms/step - loss: 0.1747 - accuracy: 0.9633 - val_loss: 0.0356 - val_accuracy: 0.9889\n",
            "Epoch 2/5\n",
            "408/408 [==============================] - 89s 219ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.0273 - val_accuracy: 0.9905\n",
            "Epoch 3/5\n",
            "408/408 [==============================] - 90s 220ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.0257 - val_accuracy: 0.9909\n",
            "Epoch 4/5\n",
            "408/408 [==============================] - 90s 220ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.0252 - val_accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "408/408 [==============================] - 90s 220ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0251 - val_accuracy: 0.9911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM model"
      ],
      "metadata": {
        "id": "QxZrdDLa05Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# create architecture\n",
        "\n",
        "lstm_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "lstm_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        weights       =  [embedding_weights],     # word embedding matrix\n",
        "                        trainable     =  True                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "lstm_model.add(LSTM(64,\n",
        "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "lstm_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "6moxpeNJySsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIiF_D3w1Iyq",
        "outputId": "9b67d1e1-85e4-4a74-e294-0f3c18708649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 64)           93440     \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, 100, 13)           845       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17928985 (68.39 MB)\n",
            "Trainable params: 17928985 (68.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "phzSeYDO1LXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUyGRdJ_1TgI",
        "outputId": "99d1eb6b-e4da-44b1-fe01-a3e41dd0affc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "408/408 [==============================] - 102s 245ms/step - loss: 0.3044 - accuracy: 0.9313 - val_loss: 0.0475 - val_accuracy: 0.9877\n",
            "Epoch 2/5\n",
            "408/408 [==============================] - 99s 244ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.0295 - val_accuracy: 0.9900\n",
            "Epoch 3/5\n",
            "408/408 [==============================] - 100s 244ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.0260 - val_accuracy: 0.9907\n",
            "Epoch 4/5\n",
            "408/408 [==============================] - 100s 244ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.0248 - val_accuracy: 0.9911\n",
            "Epoch 5/5\n",
            "408/408 [==============================] - 100s 245ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.0242 - val_accuracy: 0.9913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d44dc1ae680>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU model"
      ],
      "metadata": {
        "id": "Qwl4Iu3d6gIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "# create architecture\n",
        "\n",
        "gru_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "gru_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        weights       =  [embedding_weights],     # word embedding matrix\n",
        "                        trainable     =  True                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "gru_model.add(GRU(64,\n",
        "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "gru_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "P0jLpKqf1huh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_obLeqL16oHC",
        "outputId": "40622479-9883-466c-8c7f-4c3c80a3d63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 100, 64)           70272     \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, 100, 13)           845       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17905817 (68.31 MB)\n",
            "Trainable params: 17905817 (68.31 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0VkIWSsv60Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0npoTRJz65tQ",
        "outputId": "a654a8a8-99de-4fd7-81cd-777078222563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "408/408 [==============================] - 97s 234ms/step - loss: 0.2207 - accuracy: 0.9590 - val_loss: 0.0348 - val_accuracy: 0.9887\n",
            "Epoch 2/5\n",
            "408/408 [==============================] - 95s 234ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.0268 - val_accuracy: 0.9902\n",
            "Epoch 3/5\n",
            "408/408 [==============================] - 96s 235ms/step - loss: 0.0205 - accuracy: 0.9924 - val_loss: 0.0247 - val_accuracy: 0.9909\n",
            "Epoch 4/5\n",
            "408/408 [==============================] - 96s 234ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.0239 - val_accuracy: 0.9912\n",
            "Epoch 5/5\n",
            "408/408 [==============================] - 96s 235ms/step - loss: 0.0161 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4740761b70>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional model"
      ],
      "metadata": {
        "id": "1G03ownZ921m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# create architecture\n",
        "\n",
        "bidirectional_model = Sequential()\n",
        "\n",
        "# create embedding layer - usually the first layer in text problems\n",
        "bidirectional_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
        "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
        "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
        "                        weights       =  [embedding_weights],     # word embedding matrix\n",
        "                        trainable     =  True                    # False - don't update the embeddings\n",
        "))\n",
        "\n",
        "# add an RNN layer which contains 64 RNN cells\n",
        "bidirectional_model.add(Bidirectional(LSTM(64,\n",
        "              return_sequences=True)  # True - return whole sequence; False - return single output of the end of the sequence\n",
        "))\n",
        "\n",
        "# add time distributed (output at each sequence) layer\n",
        "bidirectional_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
      ],
      "metadata": {
        "id": "Nf61OD5V685R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bidirectional_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apORT9O5-Gxe",
        "outputId": "337a18c6-3dfc-4c20-8880-dd18f26322df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 100, 300)          17834700  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100, 128)          186880    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDi  (None, 100, 13)           1677      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18023257 (68.75 MB)\n",
            "Trainable params: 18023257 (68.75 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bidirectional_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WkSZoj9B-KfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bidirectional_model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_validation, Y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D1uqTpB-PYG",
        "outputId": "bed381bf-ad9f-4153-cb5a-d77754f43844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "408/408 [==============================] - 108s 257ms/step - loss: 0.2345 - accuracy: 0.9448 - val_loss: 0.0307 - val_accuracy: 0.9906\n",
            "Epoch 2/5\n",
            "408/408 [==============================] - 105s 258ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.0214 - val_accuracy: 0.9929\n",
            "Epoch 3/5\n",
            "408/408 [==============================] - 105s 256ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0191 - val_accuracy: 0.9935\n",
            "Epoch 4/5\n",
            "408/408 [==============================] - 105s 257ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0183 - val_accuracy: 0.9939\n",
            "Epoch 5/5\n",
            "408/408 [==============================] - 105s 258ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0180 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d44fc3f25c0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "t0q72UePA9bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = rnn_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k95NmNEL-SR2",
        "outputId": "5a8c70c8-a8bc-4ff2-b8fa-d524a636f4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339/339 [==============================] - 3s 9ms/step - loss: 0.0253 - accuracy: 0.9910\n",
            "Loss: 0.025305528193712234,\n",
            "Accuracy: 0.9910275936126709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = lstm_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HCWlY03BFiy",
        "outputId": "919f05a1-0df8-4eb8-97ef-def0495f3250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339/339 [==============================] - 6s 19ms/step - loss: 0.0241 - accuracy: 0.9913\n",
            "Loss: 0.02409767173230648,\n",
            "Accuracy: 0.991347074508667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = gru_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFiMD_c-BINb",
        "outputId": "c0ee91d9-2756-4116-cca4-356b68de344c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339/339 [==============================] - 5s 15ms/step - loss: 0.0235 - accuracy: 0.9915\n",
            "Loss: 0.023546695709228516,\n",
            "Accuracy: 0.991503119468689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = bidirectional_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNlLiUEWBKBk",
        "outputId": "364edf08-c744-4050-eb5d-8d46467375b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339/339 [==============================] - 7s 21ms/step - loss: 0.0182 - accuracy: 0.9940\n",
            "Loss: 0.018170785158872604,\n",
            "Accuracy: 0.993961751461029\n"
          ]
        }
      ]
    }
  ]
}